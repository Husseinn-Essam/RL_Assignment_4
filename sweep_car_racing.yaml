program: gym_environment.py
method: grid
metric:
  name: test_mean_reward
  goal: maximize
parameters:
  env:
    value: 'CarRacing-v3'
  
  # Algorithm selection - PPO only for Car Racing
  algorithm:
    value: 'PPO'
  
  # Number of episodes for training
  num_episodes:
    value: 300
  
  # Number of test episodes
  num-tests:
    value: 100
  
  # Learning rate sweep
  learning-rate:
    values: [0.0001, 0.0003, 0.001]
  
  # Discount factor
  gamma:
    values: [0.99, 0.995]
  
  # Batch size
  batch-size:
    values: [128, 256, 512]
  
  # PPO-specific parameters
  ppo-epochs:
    values: [5, 10, 15]
  
  entropy-coef:
    values: [0.001, 0.01]
  
  entropy-decay:
    values: [0.9, 0.95]
  
  epsilon-clip:
    values: [0.1, 0.2]
  
  max-grad-norm:
    values: [0.5, 1.0]
  
  gae-lambda: 
    values: [0.95, 0.99]
